{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Librarires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_scrap (url):\n",
    "    page = requests.get(url)\n",
    "    print(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    title = soup.find_all(['h1','h2','h3','h4','h5'])\n",
    "    title_h =[]\n",
    "    for i in title :\n",
    "        print('Heading',title.index(i))\n",
    "        print('_____________________________')\n",
    "        print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://en.wikipedia.org/wiki/Main_Page\n",
      "Heading 0\n",
      "_____________________________\n",
      "Main Page\n",
      "Heading 1\n",
      "_____________________________\n",
      "From today's featured article\n",
      "Heading 2\n",
      "_____________________________\n",
      "Did you know ...\n",
      "Heading 3\n",
      "_____________________________\n",
      "In the news\n",
      "Heading 4\n",
      "_____________________________\n",
      "On this day\n",
      "Heading 5\n",
      "_____________________________\n",
      "Today's featured picture\n",
      "Heading 6\n",
      "_____________________________\n",
      "Other areas of Wikipedia\n",
      "Heading 7\n",
      "_____________________________\n",
      "Wikipedia's sister projects\n",
      "Heading 8\n",
      "_____________________________\n",
      "Wikipedia languages\n",
      "Heading 9\n",
      "_____________________________\n",
      "Navigation menu\n",
      "Heading 10\n",
      "_____________________________\n",
      " Personal tools\n",
      "\n",
      "Heading 11\n",
      "_____________________________\n",
      " Namespaces\n",
      "\n",
      "Heading 12\n",
      "_____________________________\n",
      " Variants\n",
      "expanded\n",
      "collapsed\n",
      "\n",
      "Heading 13\n",
      "_____________________________\n",
      " Views\n",
      "\n",
      "Heading 14\n",
      "_____________________________\n",
      " More\n",
      "expanded\n",
      "collapsed\n",
      "\n",
      "Heading 15\n",
      "_____________________________\n",
      "\n",
      "Search\n",
      "\n",
      "Heading 16\n",
      "_____________________________\n",
      " Navigation\n",
      "\n",
      "Heading 17\n",
      "_____________________________\n",
      " Contribute\n",
      "\n",
      "Heading 18\n",
      "_____________________________\n",
      " Tools\n",
      "\n",
      "Heading 19\n",
      "_____________________________\n",
      " Print/export\n",
      "\n",
      "Heading 20\n",
      "_____________________________\n",
      " In other projects\n",
      "\n",
      "Heading 21\n",
      "_____________________________\n",
      " Languages\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "url = \"http://en.wikipedia.org/wiki/Main_Page\"\n",
    "headings = wiki_scrap(url)\n",
    "print(headings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_hollywood(url):\n",
    "    html = url\n",
    "    page = requests.get(html)\n",
    "    print('Responce received',page)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    mov_lst = soup.find_all('div',class_ ='lister-item mode-detail')\n",
    "    print('Scrapping Completed')\n",
    "    movie =[]\n",
    "    year =[]\n",
    "    rate = []\n",
    "    for i in mov_lst :\n",
    "        movie.append(i.h3.a.text)\n",
    "        year.append(i.h3.find('span',class_='lister-item-year text-muted unbold').text)\n",
    "        rate.append(i.find('span',class_ ='ipl-rating-star__rating').text)\n",
    "    IMDB_hollywood= pd.DataFrame({})\n",
    "    IMDB_hollywood['Name']=movie\n",
    "    IMDB_hollywood['IMDB rating']=rate\n",
    "    IMDB_hollywood['Year of release']=year\n",
    "    return IMDB_hollywood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lets find the list of best hollowood movies in IMDB\n",
      "Responce received <Response [200]>\n",
      "Scrapping Completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>IMDB rating</th>\n",
       "      <th>Year of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.3</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>9</td>\n",
       "      <td>(1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>9</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1971)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Snatch</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Le fabuleux destin d'Amélie Poulain</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Kid</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1921)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name IMDB rating Year of release\n",
       "0              The Shawshank Redemption         9.3          (1994)\n",
       "1                         The Godfather         9.2          (1972)\n",
       "2                The Godfather: Part II           9          (1974)\n",
       "3                       The Dark Knight           9          (2008)\n",
       "4                          12 Angry Men           9          (1957)\n",
       "..                                  ...         ...             ...\n",
       "95                   North by Northwest         8.3          (1959)\n",
       "96                   A Clockwork Orange         8.3          (1971)\n",
       "97                               Snatch         8.3          (2000)\n",
       "98  Le fabuleux destin d'Amélie Poulain         8.3          (2001)\n",
       "99                              The Kid         8.3          (1921)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calling Function\n",
    "print('lets find the list of best hollowood movies in IMDB')\n",
    "url ='https://www.imdb.com/list/ls091520106/'\n",
    "list_movie = imdb_hollywood(url)\n",
    "list_movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_bollywood(url):\n",
    "    html = url\n",
    "    page = requests.get(html)\n",
    "    print('Responce received',page)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    mov_lst = soup.find_all('div',class_ ='lister-item mode-detail')\n",
    "    print('Scrapping Completed')\n",
    "    movie =[]\n",
    "    year =[]\n",
    "    rate = []\n",
    "    for i in mov_lst :\n",
    "        movie.append(i.h3.a.text)\n",
    "        year.append(i.h3.find('span',class_='lister-item-year text-muted unbold').text)\n",
    "        rate.append(i.find('span',class_ ='ipl-rating-star__rating').text)\n",
    "    IMDB_bollywood= pd.DataFrame({})\n",
    "    IMDB_bollywood['Name']=movie\n",
    "    IMDB_bollywood['IMDB rating']=rate\n",
    "    IMDB_bollywood['Year of release']=year\n",
    "    return IMDB_bollywood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##FUNCTION CALLING \n",
    "print('lets find the list of best Hindi movies in IMDB')\n",
    "url =\"https://www.imdb.com/list/ls009997493/\"\n",
    "html = imdb_bollywood(url)\n",
    "html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a python program to scrap book name, author name, genre and book review of any 5 books from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_review(url) :\n",
    "    page= requests.get(url)\n",
    "    print (page)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    print ('Web Scrapping completed')\n",
    "    book_lst = soup.find_all('div',class_ ='row-fluid article-row')\n",
    "    Book_name= []\n",
    "    Author_name= []\n",
    "    Genre= []\n",
    "    Review = []\n",
    "    for  b in book_lst :\n",
    "        Book_name.append(b.h4.a.text.strip())\n",
    "        Author_name.append(b.p.text.strip())\n",
    "        Review.append(b.find('p',class_=\"excerpt\").text.strip()) \n",
    "        genre_part = b.find('p',class_='genre-links hidden-phone')\n",
    "        genre_all =genre_part.findChildren(\"a\" , recursive=False)\n",
    "        k = 'Genre :'\n",
    "        for i in genre_all:\n",
    "            k = k + i.text +' '\n",
    "        Genre.append(k)\n",
    "        if len(Book_name)>4 :\n",
    "            break\n",
    "        \n",
    "    Book_review =pd.DataFrame({})\n",
    "    Book_review['Book_name'] =Book_name\n",
    "    Book_review['Author_name']=Author_name\n",
    "    Book_review['Genre'] =Genre\n",
    "    Book_review['Review']=Review\n",
    "    return Book_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Books and Review ****\n",
      "<Response [200]>\n",
      "Web Scrapping completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_name</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>★ Carry On</td>\n",
       "      <td>John Lewis, Don Cheadle</td>\n",
       "      <td>Genre :Audio Nonfiction Essays</td>\n",
       "      <td>While John Lewis was unable to record his essa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Morning Star</td>\n",
       "      <td>Karl Ove Knausgaard, Martin Aitken</td>\n",
       "      <td>Genre :Fiction Literary Fiction</td>\n",
       "      <td>The Morning Star is dark, eerie, mesmerizing a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>★ The Beatryce Prophecy</td>\n",
       "      <td>Kate DiCamillo, Sophie Blackall</td>\n",
       "      <td>Genre :Children's Middle Grade</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Wrong End of the Telescope</td>\n",
       "      <td>Rabih Alameddine</td>\n",
       "      <td>Genre :Fiction Literary Fiction</td>\n",
       "      <td>“Writing does not force coherence onto a disco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>★ The Speckled Beauty</td>\n",
       "      <td>Rick Bragg</td>\n",
       "      <td>Genre :Nonfiction Memoir Animals</td>\n",
       "      <td>The Speckled Beauty confirms Rick Bragg’s endu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Book_name                         Author_name  \\\n",
       "0                      ★ Carry On             John Lewis, Don Cheadle   \n",
       "1                The Morning Star  Karl Ove Knausgaard, Martin Aitken   \n",
       "2         ★ The Beatryce Prophecy     Kate DiCamillo, Sophie Blackall   \n",
       "3  The Wrong End of the Telescope                    Rabih Alameddine   \n",
       "4           ★ The Speckled Beauty                          Rick Bragg   \n",
       "\n",
       "                               Genre  \\\n",
       "0    Genre :Audio Nonfiction Essays    \n",
       "1   Genre :Fiction Literary Fiction    \n",
       "2    Genre :Children's Middle Grade    \n",
       "3   Genre :Fiction Literary Fiction    \n",
       "4  Genre :Nonfiction Memoir Animals    \n",
       "\n",
       "                                              Review  \n",
       "0  While John Lewis was unable to record his essa...  \n",
       "1  The Morning Star is dark, eerie, mesmerizing a...  \n",
       "2                                                     \n",
       "3  “Writing does not force coherence onto a disco...  \n",
       "4  The Speckled Beauty confirms Rick Bragg’s endu...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('**** Books and Review ****')\n",
    "url = 'https://bookpage.com/reviews'\n",
    "review = book_review(url)\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "\n",
    "\n",
    "i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def men_team_rtgs(url):\n",
    "    page =requests.get(url)\n",
    "    print('Response received :',page)\n",
    "    soup =BeautifulSoup(page.content)\n",
    "    rank=[]\n",
    "    country=[]\n",
    "    matches =[]\n",
    "    points =[]\n",
    "    rating=[]\n",
    "    others =[]\n",
    "    best_team = soup.find_all('tr',class_=\"rankings-block__banner\")\n",
    "    for i in best_team :\n",
    "        rnk =i.find('td',class_='rankings-block__banner--pos')\n",
    "        rank.append(rnk.text)\n",
    "        ctry = i.find('span',class_ ='u-hide-phablet')\n",
    "        country.append(ctry.text.strip())\n",
    "        mtch = i.find('td',class_ ='rankings-block__banner--matches')\n",
    "        matches.append(mtch.text.strip())\n",
    "        pts = i.find('td',class_ ='rankings-block__banner--points')\n",
    "        points.append(pts.text.strip())\n",
    "        rate = i.find('td',class_ ='rankings-block__banner--rating u-text-right')\n",
    "        rating.append(rate.text.strip())\n",
    "    team_odi = soup.find_all('tr',class_='table-body')\n",
    "    for i in team_odi :\n",
    "        rnk =i.find('td',class_='table-body__cell table-body__cell--position u-text-right')\n",
    "        rank.append(rnk.text)\n",
    "        ctry = i.find('span',class_ ='u-hide-phablet')\n",
    "        country.append(ctry.text.strip())\n",
    "        rate = i.find('td',class_ ='table-body__cell u-text-right rating')\n",
    "        rating.append(rate.text.strip())\n",
    "        other = i.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "        for j in other :\n",
    "            others.append(j.text)\n",
    "        if len(rating) == 10:\n",
    "            break\n",
    "    mtch = others[0::2]\n",
    "    pnts = others[1::2]\n",
    "    matches =matches.extend(mtch)\n",
    "    points =points.extend(pnts)\n",
    "    ODI_MEN_TEAM_RATINGS = pd.DataFrame([])\n",
    "    ODI_MEN_TEAM_RATINGS[\"rank\"] =rank\n",
    "    ODI_MEN_TEAM_RATINGS[\"country\"] =country\n",
    "    ODI_MEN_TEAM_RATINGS[\"matches\"] =matches\n",
    "    ODI_MEN_TEAM_RATINGS[\"points\"] =points\n",
    "    ODI_MEN_TEAM_RATINGS[\"rating\"] =rating\n",
    "    return ODI_MEN_TEAM_RATINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** ICC TEAM RATING MEN ODI \n",
      "Response received : <Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>country</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>England</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Australia</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>West Indies</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rank       country matches points rating\n",
       "0    1   New Zealand    None   None    121\n",
       "1    2       England    None   None    119\n",
       "2    3     Australia    None   None    116\n",
       "3    4         India    None   None    113\n",
       "4    5  South Africa    None   None     98\n",
       "5    6      Pakistan    None   None     93\n",
       "6    7    Bangladesh    None   None     91\n",
       "7    8   West Indies    None   None     84\n",
       "8    9     Sri Lanka    None   None     83\n",
       "9   10   Afghanistan    None   None     62"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('****** ICC TEAM RATING MEN ODI ')\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "ICC_MEN_ODI_TEAM_RANK= men_team_rtgs(url)\n",
    "ICC_MEN_ODI_TEAM_RANK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Top 10 ODI Batsmen in men along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icc_men_bat_odi(url) :\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    w_best_bat =  soup.find_all('tr',class_='rankings-block__banner')\n",
    "    rank =[]\n",
    "    name=[]\n",
    "    country=[]\n",
    "    points =[]\n",
    "    for i in w_best_bat :\n",
    "        rnk = i.find('td',class_ ='rankings-block__position')\n",
    "        nme = i.find('div',class_ ='rankings-block__banner--name-large')\n",
    "        ctr = i.find('div',class_ ='rankings-block__banner--nationality')\n",
    "        pts = i.find('div',class_ ='rankings-block__banner--rating')\n",
    "        rank.append(rnk.text.strip())\n",
    "        name.append(nme.text.strip())\n",
    "        country.append(ctr.text.strip())\n",
    "        points.append(pts.text.strip())\n",
    "    w_bat =  soup.find_all('tr',class_='table-body')\n",
    "    for i in w_bat :\n",
    "        rnk = i.find('td',class_ ='table-body__cell table-body__cell--position u-text-right')\n",
    "        nme = i.find('a')\n",
    "        ctr = i.find('span',class_ ='table-body__logo-text')\n",
    "        pts = i.find('td',class_ ='table-body__cell rating')\n",
    "        rank.append(rnk.text.strip())\n",
    "        name.append(nme.text.strip())\n",
    "        country.append(ctr.text.strip())\n",
    "        points.append(pts.text.strip())\n",
    "        if len(points) == 10:\n",
    "            break\n",
    "    ODI_MEN_ODI__BAT_Ratings = pd.DataFrame([])\n",
    "    ODI_MEN_ODI__BAT_Ratings[\"Position\"] =rank\n",
    "    ODI_MEN_ODI__BAT_Ratings[\"Player Name\"] =name\n",
    "    ODI_MEN_ODI__BAT_Ratings[\"Team\"] =country\n",
    "    ODI_MEN_ODI__BAT_Ratings[\"Rating\"] =points\n",
    "    return ODI_MEN_ODI__BAT_Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ODI BATESMEN RATING')\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "rank =icc_men_bat_odi(url)\n",
    "rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii) Top 10 ODI bowlers along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icc_men_bowl_odi(url) :\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    best_bowl= soup.find_all('tr',class_='rankings-block__banner')\n",
    "    rank =[]\n",
    "    name=[]\n",
    "    country=[]\n",
    "    points =[]\n",
    "    for i in best_bowl :\n",
    "        rnk = i.find('td',class_ ='rankings-block__position')\n",
    "        nme = i.find('div',class_ ='rankings-block__banner--name-large')\n",
    "        ctr = i.find('div',class_ ='rankings-block__banner--nationality')\n",
    "        pts = i.find('div',class_ ='rankings-block__banner--rating')\n",
    "        rank.append(rnk.text.strip())\n",
    "        name.append(nme.text.strip())\n",
    "        country.append(ctr.text.strip())\n",
    "        points.append(pts.text.strip())\n",
    "    bowl_odi = soup.find_all('tr',class_='table-body')\n",
    "    for i in bowl_odi :\n",
    "        rnk = i.find('td',class_ ='table-body__cell table-body__cell--position u-text-right')\n",
    "        nme = i.find('a')\n",
    "        ctr = i.find('span',class_ ='table-body__logo-text')\n",
    "        pts = i.find('td',class_ ='table-body__cell rating')\n",
    "        rank.append(rnk.text.strip())\n",
    "        name.append(nme.text.strip())\n",
    "        country.append(ctr.text.strip())\n",
    "        points.append(pts.text.strip())\n",
    "        if len(rank) == 10:\n",
    "            break\n",
    "    ODI_BOWLING_Ratings = pd.DataFrame([])\n",
    "    ODI_BOWLING_Ratings[\"Position\"] =rank\n",
    "    ODI_BOWLING_Ratings[\"Player Name\"] =name\n",
    "    ODI_BOWLING_Ratings[\"Team\"] =country\n",
    "    ODI_BOWLING_Ratings[\"Rating\"] =points\n",
    "    return ODI_BOWLING_Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ODI Bowler RATING')\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "rank =icc_men_bowl_odi(url)\n",
    "rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "\n",
    "\n",
    "i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def women_team_rtgs(url):\n",
    "    page =requests.get(url)\n",
    "    print('Response received :',page)\n",
    "    soup =BeautifulSoup(page.content)\n",
    "    rank=[]\n",
    "    country=[]\n",
    "    matches =[]\n",
    "    points =[]\n",
    "    rating=[]\n",
    "    others =[]\n",
    "    best_team = soup.find_all('tr',class_=\"rankings-block__banner\")\n",
    "    for i in best_team :\n",
    "        rnk =i.find('td',class_='rankings-block__banner--pos')\n",
    "        rank.append(rnk.text)\n",
    "        ctry = i.find('span',class_ ='u-hide-phablet')\n",
    "        country.append(ctry.text.strip())\n",
    "        mtch = i.find('td',class_ ='rankings-block__banner--matches')\n",
    "        matches.append(mtch.text.strip())\n",
    "        pts = i.find('td',class_ ='rankings-block__banner--points')\n",
    "        points.append(pts.text.strip())\n",
    "        rate = i.find('td',class_ ='rankings-block__banner--rating u-text-right')\n",
    "        rating.append(rate.text.strip())\n",
    "    team_odi = soup.find_all('tr',class_='table-body')\n",
    "    for i in team_odi :\n",
    "        rnk =i.find('td',class_='table-body__cell table-body__cell--position u-text-right')\n",
    "        rank.append(rnk.text)\n",
    "        ctry = i.find('span',class_ ='u-hide-phablet')\n",
    "        country.append(ctry.text.strip())\n",
    "        rate = i.find('td',class_ ='table-body__cell u-text-right rating')\n",
    "        rating.append(rate.text.strip())\n",
    "        other = i.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "        for j in other :\n",
    "            others.append(j.text)\n",
    "        if len(rating) == 10:\n",
    "            break\n",
    "    mtch = others[0::2]\n",
    "    pnts = others[1::2]\n",
    "    matches =matches.extend(mtch)\n",
    "    points =points.extend(pnts)\n",
    "    ODI_WOMEN_TEAM_RATINGS = pd.DataFrame([])\n",
    "    ODI_WOMEN_TEAM_RATINGS[\"rank\"] =rank\n",
    "    ODI_WOMEN_TEAM_RATINGS[\"country\"] =country\n",
    "    ODI_WOMEN_TEAM_RATINGS[\"matches\"] =matches\n",
    "    ODI_WOMEN_TEAM_RATINGS[\"points\"] =points\n",
    "    ODI_WOMEN_TEAM_RATINGS[\"rating\"] =rating\n",
    "    return ODI_WOMEN_TEAM_RATINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('****** ICC TEAM RATING WOMEN ODI ')\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "ICC_WOMEN_ODI_TEAM_RANK= women_team_rtgs(url)\n",
    "ICC_WOMEN_ODI_TEAM_RANK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ii) Top 10 women’s ODI players along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_odi_bat(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    w_best_bat =  soup.find_all('tr',class_='rankings-block__banner')\n",
    "    rank =[]\n",
    "    name=[]\n",
    "    country=[]\n",
    "    points =[]\n",
    "    for i in w_best_bat :\n",
    "        rnk = i.find('td',class_ ='rankings-block__position')\n",
    "        nme = i.find('div',class_ ='rankings-block__banner--name-large')\n",
    "        ctr = i.find('div',class_ ='rankings-block__banner--nationality')\n",
    "        pts = i.find('div',class_ ='rankings-block__banner--rating')\n",
    "        rank.append(rnk.text.strip())\n",
    "        name.append(nme.text.strip())\n",
    "        country.append(ctr.text.strip())\n",
    "        points.append(pts.text.strip())\n",
    "    w_bat =  soup.find_all('tr',class_='table-body')\n",
    "    for i in w_bat :\n",
    "        rnk = i.find('td',class_ ='table-body__cell table-body__cell--position u-text-right')\n",
    "        nme = i.find('a')\n",
    "        ctr = i.find('span',class_ ='table-body__logo-text')\n",
    "        pts = i.find('td',class_ ='table-body__cell rating')\n",
    "        rank.append(rnk.text.strip())\n",
    "        name.append(nme.text.strip())\n",
    "        country.append(ctr.text.strip())\n",
    "        points.append(pts.text.strip())\n",
    "        if len(points) == 10:\n",
    "            break\n",
    "    ODI_Women_ODI__BAT_Ratings = pd.DataFrame([])\n",
    "    ODI_Women_ODI__BAT_Ratings[\"Position\"] =rank\n",
    "    ODI_Women_ODI__BAT_Ratings[\"Player Name\"] =name\n",
    "    ODI_Women_ODI__BAT_Ratings[\"Team\"] =country\n",
    "    ODI_Women_ODI__BAT_Ratings[\"Rating\"] =points\n",
    "    return ODI_Women_ODI__BAT_Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w_odi_bat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-a4c8c87533f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mwomen_odi_bat\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mw_odi_bat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mwomen_odi_bat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'w_odi_bat' is not defined"
     ]
    }
   ],
   "source": [
    "url =\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "women_odi_bat= w_odi_bat(url)\n",
    "women_odi_bat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_odi_all (url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    w_best_all_odi =  soup.find_all('tr',class_='rankings-block__banner')\n",
    "    rank =[]\n",
    "    name=[]\n",
    "    country=[]\n",
    "    points =[]\n",
    "    for i in w_best_all_odi :\n",
    "        rnk = i.find('td',class_ ='rankings-block__position')\n",
    "        nme = i.find('div',class_ ='rankings-block__banner--name-large')\n",
    "        ctr = i.find('div',class_ ='rankings-block__banner--nationality')\n",
    "        pts = i.find('div',class_ ='rankings-block__banner--rating')\n",
    "        rank.append(rnk.text.strip())\n",
    "        name.append(nme.text.strip())\n",
    "        country.append(ctr.text.strip())\n",
    "        points.append(pts.text.strip())\n",
    "    w_all_odi =  soup.find_all('tr',class_='table-body')\n",
    "    for i in w_all_odi :\n",
    "        rnk = i.find('td',class_ ='table-body__cell table-body__cell--position u-text-right')\n",
    "        nme = i.find('a')\n",
    "        ctr = i.find('span',class_ ='table-body__logo-text')\n",
    "        pts = i.find('td',class_ ='table-body__cell rating')\n",
    "        rank.append(rnk.text.strip())\n",
    "        name.append(nme.text.strip())\n",
    "        country.append(ctr.text.strip())\n",
    "        points.append(pts.text.strip())\n",
    "        if len(points) == 10:\n",
    "            break\n",
    "    ODI_Women_ODI_Ratings = pd.DataFrame([])\n",
    "    ODI_Women_ODI_Ratings[\"Position\"] =rank\n",
    "    ODI_Women_ODI_Ratings[\"Player Name\"] =name\n",
    "    ODI_Women_ODI_Ratings[\"Team\"] =country\n",
    "    ODI_Women_ODI_Ratings[\"Rating\"] =points\n",
    "    return ODI_Women_ODI_Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2\\n        \\n\\n\\n\\nThis player has moved down ...</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3\\n        \\n\\n\\n\\nThis player has moved up in...</td>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4\\n        \\n\\n\\n\\nThis player has moved down ...</td>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Position       Player Name Team  \\\n",
       "0                                                  1    Marizanne Kapp   SA   \n",
       "1  2\\n        \\n\\n\\n\\nThis player has moved down ...      Ellyse Perry  AUS   \n",
       "2  3\\n        \\n\\n\\n\\nThis player has moved up in...    Natalie Sciver  ENG   \n",
       "3  4\\n        \\n\\n\\n\\nThis player has moved down ...   Stafanie Taylor   WI   \n",
       "4                                                  5     Deepti Sharma  IND   \n",
       "5                                                  6     Jess Jonassen  AUS   \n",
       "6                                                  7  Dane van Niekerk   SA   \n",
       "7                                                  8  Ashleigh Gardner  AUS   \n",
       "8                                                  9     Sophie Devine   NZ   \n",
       "9                                                 10   Katherine Brunt  ENG   \n",
       "\n",
       "  Rating  \n",
       "0    419  \n",
       "1    418  \n",
       "2    365  \n",
       "3    364  \n",
       "4    331  \n",
       "5    307  \n",
       "6    270  \n",
       "7    252  \n",
       "8    242  \n",
       "9    239  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "all_rounder_rank= w_odi_all(url)\n",
    "all_rounder_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Write a python program to extract information about the local weather from the National Weather Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_service(url):\n",
    "    html = url\n",
    "    page = requests.get(html)\n",
    "    print('Website Status',page)\n",
    "    soup =  BeautifulSoup(page.content)\n",
    "    period_l=soup.find_all('p',class_ = 'period-name')\n",
    "    sdesc_l = soup.find_all('p','short-desc')\n",
    "    t_low =soup.find_all('p','temp temp-low')\n",
    "    t_high =soup.find_all('p','temp temp-high')\n",
    "    print('Scrapping Completed')\n",
    "    period =[]\n",
    "    for i in period_l:\n",
    "        period.append(i.text)\n",
    "    sdesc =[]\n",
    "    for j in sdesc_l:\n",
    "        sdesc.append(j.text)\n",
    "    min_temp = []\n",
    "    for k in t_low :\n",
    "        min_temp.append(k.text)\n",
    "    max_temp = []\n",
    "    for k in t_high :\n",
    "        max_temp.append(k.text)\n",
    "    temp_f = []\n",
    "    if period[0]=='Today' :\n",
    "        temp_f =[None]*(len(min_temp)+len(max_temp))\n",
    "        temp_f[::2]= max_temp\n",
    "        temp_f[1::2]= min_temp\n",
    "    else:\n",
    "        temp_f =[None]*(len(min_temp)+len(max_temp))\n",
    "        temp_f[::2]= min_temp\n",
    "        temp_f[1::2]= max_temp\n",
    "    weather = pd.DataFrame({})\n",
    "    weather['Period'] =period\n",
    "    weather['Tempareture'] =temp_f\n",
    "    #weather['Max_Temp'] =max_temp\n",
    "    weather['Short_Descriptipn'] =sdesc\n",
    "    return weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Weather Forcast ****\n",
      "Website Status <Response [200]>\n",
      "Scrapping Completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Tempareture</th>\n",
       "      <th>Short_Descriptipn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today</td>\n",
       "      <td>High: 78 °F</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tonight</td>\n",
       "      <td>Low: 61 °F</td>\n",
       "      <td>Mostly Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>High: 87 °F</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TuesdayNight</td>\n",
       "      <td>Low: 58 °F</td>\n",
       "      <td>Mostly Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>High: 72 °F</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WednesdayNight</td>\n",
       "      <td>Low: 56 °F</td>\n",
       "      <td>Mostly Clearand Breezythen PartlyCloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>High: 75 °F</td>\n",
       "      <td>Mostly Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ThursdayNight</td>\n",
       "      <td>Low: 58 °F</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Friday</td>\n",
       "      <td>High: 73 °F</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Period  Tempareture                        Short_Descriptipn\n",
       "0           Today  High: 78 °F                                    Sunny\n",
       "1         Tonight   Low: 61 °F                             Mostly Clear\n",
       "2         Tuesday  High: 87 °F                                    Sunny\n",
       "3    TuesdayNight   Low: 58 °F                             Mostly Clear\n",
       "4       Wednesday  High: 72 °F                                    Sunny\n",
       "5  WednesdayNight   Low: 56 °F  Mostly Clearand Breezythen PartlyCloudy\n",
       "6        Thursday  High: 75 °F                             Mostly Sunny\n",
       "7   ThursdayNight   Low: 58 °F                            Partly Cloudy\n",
       "8          Friday  High: 73 °F                                    Sunny"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('**** Weather Forcast ****')\n",
    "weather_url = \"https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YM2fa_LivDc\" \n",
    "report = weather_service(weather_url)\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title, company name, CTC, and apply date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wb_scrap(url):\n",
    "    page = requests.get(url)\n",
    "    print(page)\n",
    "    soup= BeautifulSoup(page.content)\n",
    "    title_all = soup.find_all('div',class_= \"heading_4_5 profile\")\n",
    "    print ('Scrapping Completed')\n",
    "    job_title = []\n",
    "    for i in title_all :\n",
    "        job_title.append(i.text.replace('\\n',''))\n",
    "    comp_all = soup.find_all('a',class_=\"link_display_like_text\")\n",
    "    company =[]\n",
    "    for j in comp_all:\n",
    "        company.append(j.text.strip())\n",
    "    loc_all = soup.find_all('p',id ='location_names')\n",
    "    location =[]\n",
    "    for l in loc_all :\n",
    "        location.append(l.text.strip())\n",
    "    job_det =soup.find_all('div',class_ =\"item_body\")\n",
    "    j_details=[]\n",
    "    for i in job_det :\n",
    "        job_attr=i.text.strip().replace('\\xa0' ,' ')\n",
    "        j_details.append(job_attr)\n",
    "    start = []\n",
    "    pkg =[]\n",
    "    doj = []\n",
    "    start = j_details[0::3]\n",
    "    pkg = j_details[1::3]\n",
    "    doj = j_details[2::3]\n",
    "    Intern = pd.DataFrame({})\n",
    "    Intern['Company']= company\n",
    "    Intern['Job-Title']=job_title\n",
    "    Intern['Location']=location\n",
    "    Intern['Starts From ']=start\n",
    "    Intern['CTC']=pkg\n",
    "    Intern['Last Date to apply']=doj\n",
    "    \n",
    "    \n",
    "    return Intern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "Scrapping Completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job-Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Starts From</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Last Date to apply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decathlon Sports India</td>\n",
       "      <td>Omni Sport Leader - Running/Walking</td>\n",
       "      <td>Jaipur, Ajmer</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 3.4 LPA</td>\n",
       "      <td>7 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Backflip Design Studio</td>\n",
       "      <td>Junior Graphic Designer</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>20 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HireTale</td>\n",
       "      <td>Recruitment Executive</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>5 - 6 LPA</td>\n",
       "      <td>20 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IPayTotal</td>\n",
       "      <td>Lead Generation Specialist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>20 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Enaviya Information Technologies Private Limited</td>\n",
       "      <td>Junior Software Developer</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>20 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Boongg</td>\n",
       "      <td>Application Developer</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>4 - 6 LPA</td>\n",
       "      <td>20 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UFaber Edutech</td>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Kolkata, Bangalore, Mumbai</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>20 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PlanetSpark</td>\n",
       "      <td>Curriculum Developer (English)</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>6.4 LPA</td>\n",
       "      <td>20 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jaza Software</td>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>4.25 - 5.5 LPA</td>\n",
       "      <td>20 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Krishworks</td>\n",
       "      <td>Flutter Developer</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>20 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Checkmate Industrial Guards Private Limited</td>\n",
       "      <td>Area Executive</td>\n",
       "      <td>Delhi, Gurgaon, Noida</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 3.1 LPA</td>\n",
       "      <td>18 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kaholas</td>\n",
       "      <td>Business Development And Research Executive</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>18 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Stockarea</td>\n",
       "      <td>Frontend Developer (Vue.js)</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>4 - 4.6 LPA</td>\n",
       "      <td>18 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Zenguruz Online Private Limited</td>\n",
       "      <td>Executive Assistant To Founder</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>18 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NLET Initiatives LLP</td>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>18 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PlanetSpark</td>\n",
       "      <td>Community Management Associate</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>6.4 LPA</td>\n",
       "      <td>18 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Forage AI</td>\n",
       "      <td>Data Specialist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>18 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MiM-Essay</td>\n",
       "      <td>Digital Marketing Associate</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>4.2 - 5 LPA</td>\n",
       "      <td>18 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EnWe Clean Technologies Private Limited</td>\n",
       "      <td>Process &amp; Proposal Engineer</td>\n",
       "      <td>Faridabad, Delhi, Gurgaon, Greater Noida, Noida</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3.6 - 3.7 LPA</td>\n",
       "      <td>18 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pragna Technologies</td>\n",
       "      <td>US Recruiter Trainee</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 6 LPA</td>\n",
       "      <td>17 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Open Door Education</td>\n",
       "      <td>Sales Associate</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>17 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Nyx Wolves</td>\n",
       "      <td>Junior Project Delivery Manager &amp; Customer Rel...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>17 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Nyx Wolves</td>\n",
       "      <td>IT Project Manager</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3.7 - 4.7 LPA</td>\n",
       "      <td>17 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The Shirt Studio</td>\n",
       "      <td>Fashion Designer</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>17 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Vidhata Educare</td>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>17 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NNIIT</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>17 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Noisy Lion</td>\n",
       "      <td>Graphic Designer</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 6 LPA</td>\n",
       "      <td>17 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Leadgenerator</td>\n",
       "      <td>Content Writer (Sales)</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>17 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>HumLife360</td>\n",
       "      <td>Diabetes Lifestyle Behavioral Coach</td>\n",
       "      <td>Pune, Mumbai</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3.5 - 4 LPA</td>\n",
       "      <td>17 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Digite Infotech Private Limited</td>\n",
       "      <td>Functional Executive Trainee</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3.5 - 4.5 LPA</td>\n",
       "      <td>16 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Jalpan Agro Foods Preparation</td>\n",
       "      <td>Field Sales Associate</td>\n",
       "      <td>Bhubaneswar, Bokaro Steel City, Dhanbad, Asansol</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 3.2 LPA</td>\n",
       "      <td>16 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Redwood Algorithms</td>\n",
       "      <td>General Management Associate</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>4 - 5 LPA</td>\n",
       "      <td>16 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Devship (OPC) Private Limited</td>\n",
       "      <td>Software Developer (Full Stack Web Development)</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>16 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Educase India</td>\n",
       "      <td>Junior Mobile App Developer</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>16 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Wingman</td>\n",
       "      <td>Junior Backend Developer</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>7 - 12 LPA</td>\n",
       "      <td>16 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LionCircuits</td>\n",
       "      <td>Junior Full Stack Developer</td>\n",
       "      <td>Bangalore, Chennai</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>16 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Spottabl</td>\n",
       "      <td>Supply Associate</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>16 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>GMoney Private Limited</td>\n",
       "      <td>Assistant Manager - Sales</td>\n",
       "      <td>Delhi, Pune, Mumbai, Bangalore</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3.5 - 3.76 LPA</td>\n",
       "      <td>16 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UFaber Edutech</td>\n",
       "      <td>Inside Sales Executive</td>\n",
       "      <td>Ahmedabad, Kolkata, Bangalore, Hyderabad, Mumbai</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>16 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Chittoo Tech</td>\n",
       "      <td>Junior Full Stack Developer</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3.6 - 4.2 LPA</td>\n",
       "      <td>16 Oct' 21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Company  \\\n",
       "0                             Decathlon Sports India   \n",
       "1                             Backflip Design Studio   \n",
       "2                                           HireTale   \n",
       "3                                          IPayTotal   \n",
       "4   Enaviya Information Technologies Private Limited   \n",
       "5                                             Boongg   \n",
       "6                                     UFaber Edutech   \n",
       "7                                        PlanetSpark   \n",
       "8                                      Jaza Software   \n",
       "9                                         Krishworks   \n",
       "10       Checkmate Industrial Guards Private Limited   \n",
       "11                                           Kaholas   \n",
       "12                                         Stockarea   \n",
       "13                   Zenguruz Online Private Limited   \n",
       "14                              NLET Initiatives LLP   \n",
       "15                                       PlanetSpark   \n",
       "16                                         Forage AI   \n",
       "17                                         MiM-Essay   \n",
       "18           EnWe Clean Technologies Private Limited   \n",
       "19                               Pragna Technologies   \n",
       "20                               Open Door Education   \n",
       "21                                        Nyx Wolves   \n",
       "22                                        Nyx Wolves   \n",
       "23                                  The Shirt Studio   \n",
       "24                                   Vidhata Educare   \n",
       "25                                             NNIIT   \n",
       "26                                        Noisy Lion   \n",
       "27                                     Leadgenerator   \n",
       "28                                        HumLife360   \n",
       "29                   Digite Infotech Private Limited   \n",
       "30                     Jalpan Agro Foods Preparation   \n",
       "31                                Redwood Algorithms   \n",
       "32                     Devship (OPC) Private Limited   \n",
       "33                                     Educase India   \n",
       "34                                           Wingman   \n",
       "35                                      LionCircuits   \n",
       "36                                          Spottabl   \n",
       "37                            GMoney Private Limited   \n",
       "38                                    UFaber Edutech   \n",
       "39                                      Chittoo Tech   \n",
       "\n",
       "                                            Job-Title  \\\n",
       "0                Omni Sport Leader - Running/Walking    \n",
       "1                            Junior Graphic Designer    \n",
       "2                              Recruitment Executive    \n",
       "3                         Lead Generation Specialist    \n",
       "4                          Junior Software Developer    \n",
       "5                              Application Developer    \n",
       "6                     Business Development Executive    \n",
       "7                     Curriculum Developer (English)    \n",
       "8                               Full Stack Developer    \n",
       "9                                  Flutter Developer    \n",
       "10                                    Area Executive    \n",
       "11       Business Development And Research Executive    \n",
       "12                       Frontend Developer (Vue.js)    \n",
       "13                    Executive Assistant To Founder    \n",
       "14                    Business Development Executive    \n",
       "15                    Community Management Associate    \n",
       "16                                   Data Specialist    \n",
       "17                       Digital Marketing Associate    \n",
       "18                       Process & Proposal Engineer    \n",
       "19                              US Recruiter Trainee    \n",
       "20                                   Sales Associate    \n",
       "21  Junior Project Delivery Manager & Customer Rel...   \n",
       "22                                IT Project Manager    \n",
       "23                                  Fashion Designer    \n",
       "24                    Business Development Executive    \n",
       "25                                           Teacher    \n",
       "26                                  Graphic Designer    \n",
       "27                            Content Writer (Sales)    \n",
       "28               Diabetes Lifestyle Behavioral Coach    \n",
       "29                      Functional Executive Trainee    \n",
       "30                             Field Sales Associate    \n",
       "31                      General Management Associate    \n",
       "32   Software Developer (Full Stack Web Development)    \n",
       "33                       Junior Mobile App Developer    \n",
       "34                          Junior Backend Developer    \n",
       "35                       Junior Full Stack Developer    \n",
       "36                                  Supply Associate    \n",
       "37                         Assistant Manager - Sales    \n",
       "38                            Inside Sales Executive    \n",
       "39                       Junior Full Stack Developer    \n",
       "\n",
       "                                            Location        Starts From   \\\n",
       "0                                      Jaipur, Ajmer  Starts Immediately   \n",
       "1                                          Bangalore  Starts Immediately   \n",
       "2                                             Jaipur  Starts Immediately   \n",
       "3                                             Remote  Starts Immediately   \n",
       "4                                          Bangalore  Starts Immediately   \n",
       "5                                               Pune  Starts Immediately   \n",
       "6                         Kolkata, Bangalore, Mumbai  Starts Immediately   \n",
       "7                                            Gurgaon  Starts Immediately   \n",
       "8                                          Bangalore  Starts Immediately   \n",
       "9                                             Remote  Starts Immediately   \n",
       "10                             Delhi, Gurgaon, Noida  Starts Immediately   \n",
       "11                                             Delhi  Starts Immediately   \n",
       "12                                            Remote  Starts Immediately   \n",
       "13                                            Remote  Starts Immediately   \n",
       "14                                            Jaipur  Starts Immediately   \n",
       "15                                           Gurgaon  Starts Immediately   \n",
       "16                                            Remote  Starts Immediately   \n",
       "17                                             Delhi  Starts Immediately   \n",
       "18   Faridabad, Delhi, Gurgaon, Greater Noida, Noida  Starts Immediately   \n",
       "19                                         Bangalore  Starts Immediately   \n",
       "20                                           Gurgaon  Starts Immediately   \n",
       "21                                            Remote  Starts Immediately   \n",
       "22                                            Remote  Starts Immediately   \n",
       "23                                         Bangalore  Starts Immediately   \n",
       "24                                         Ahmedabad  Starts Immediately   \n",
       "25                                         Hyderabad  Starts Immediately   \n",
       "26                                             Noida  Starts Immediately   \n",
       "27                                            Remote  Starts Immediately   \n",
       "28                                      Pune, Mumbai  Starts Immediately   \n",
       "29                                            Remote  Starts Immediately   \n",
       "30  Bhubaneswar, Bokaro Steel City, Dhanbad, Asansol  Starts Immediately   \n",
       "31                                            Remote  Starts Immediately   \n",
       "32                                           Chennai  Starts Immediately   \n",
       "33                                            Remote  Starts Immediately   \n",
       "34                                            Remote  Starts Immediately   \n",
       "35                                Bangalore, Chennai  Starts Immediately   \n",
       "36                                            Remote  Starts Immediately   \n",
       "37                    Delhi, Pune, Mumbai, Bangalore  Starts Immediately   \n",
       "38  Ahmedabad, Kolkata, Bangalore, Hyderabad, Mumbai  Starts Immediately   \n",
       "39                                         Bangalore  Starts Immediately   \n",
       "\n",
       "               CTC Last Date to apply  \n",
       "0      3 - 3.4 LPA          7 Oct' 21  \n",
       "1      3 - 3.5 LPA         20 Oct' 21  \n",
       "2        5 - 6 LPA         20 Oct' 21  \n",
       "3        3 - 4 LPA         20 Oct' 21  \n",
       "4            3 LPA         20 Oct' 21  \n",
       "5        4 - 6 LPA         20 Oct' 21  \n",
       "6        3 - 4 LPA         20 Oct' 21  \n",
       "7          6.4 LPA         20 Oct' 21  \n",
       "8   4.25 - 5.5 LPA         20 Oct' 21  \n",
       "9        3 - 5 LPA         20 Oct' 21  \n",
       "10     3 - 3.1 LPA         18 Oct' 21  \n",
       "11           3 LPA         18 Oct' 21  \n",
       "12     4 - 4.6 LPA         18 Oct' 21  \n",
       "13           3 LPA         18 Oct' 21  \n",
       "14       3 - 4 LPA         18 Oct' 21  \n",
       "15         6.4 LPA         18 Oct' 21  \n",
       "16           3 LPA         18 Oct' 21  \n",
       "17     4.2 - 5 LPA         18 Oct' 21  \n",
       "18   3.6 - 3.7 LPA         18 Oct' 21  \n",
       "19       3 - 6 LPA         17 Oct' 21  \n",
       "20       3 - 4 LPA         17 Oct' 21  \n",
       "21     3 - 3.6 LPA         17 Oct' 21  \n",
       "22   3.7 - 4.7 LPA         17 Oct' 21  \n",
       "23     3 - 3.6 LPA         17 Oct' 21  \n",
       "24     3 - 3.5 LPA         17 Oct' 21  \n",
       "25       3 - 5 LPA         17 Oct' 21  \n",
       "26       3 - 6 LPA         17 Oct' 21  \n",
       "27           3 LPA         17 Oct' 21  \n",
       "28     3.5 - 4 LPA         17 Oct' 21  \n",
       "29   3.5 - 4.5 LPA         16 Oct' 21  \n",
       "30     3 - 3.2 LPA         16 Oct' 21  \n",
       "31       4 - 5 LPA         16 Oct' 21  \n",
       "32       3 - 4 LPA         16 Oct' 21  \n",
       "33           3 LPA         16 Oct' 21  \n",
       "34      7 - 12 LPA         16 Oct' 21  \n",
       "35       3 - 5 LPA         16 Oct' 21  \n",
       "36       3 - 4 LPA         16 Oct' 21  \n",
       "37  3.5 - 3.76 LPA         16 Oct' 21  \n",
       "38       3 - 4 LPA         16 Oct' 21  \n",
       "39   3.6 - 4.2 LPA         16 Oct' 21  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_chk = \"https://internshala.com/fresher-jobs\"\n",
    "data = wb_scrap(url_chk)\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 .Write a python program to scrape house details from mentioned url. It should include house title, location, area, emi and price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_broker(url):\n",
    "    page = requests.get(url)\n",
    "    print(page)\n",
    "    soup= BeautifulSoup(page.content)\n",
    "    prop_title = soup.find_all('div',class_ ='nb__2JHKO')\n",
    "    title = []\n",
    "    for i in prop_title :\n",
    "        title.append(i.h2.span.text)\n",
    "    sqft = soup.find_all('div',class_='nb__3oNyC')\n",
    "    area = []\n",
    "    for i in sqft :\n",
    "        area.append(i.text)\n",
    "    prop_emi = soup.find_all('div',id ='roomType')\n",
    "    emi = []\n",
    "    for i in prop_emi :\n",
    "        emi.append(i.text)\n",
    "    prop_loc = soup.find_all('div',class_ ='nb__2CMjv')\n",
    "    loc = []\n",
    "    for i in prop_loc :\n",
    "        loc.append(i.text)\n",
    "    prop_price =soup.find_all(\"div\", id =\"minDeposit\")\n",
    "    price = []\n",
    "    for i in prop_price :\n",
    "        j = i.find('div',class_='font-semi-bold heading-6')\n",
    "        price.append(j.text)\n",
    "    NO_BROKER_LIST =pd.DataFrame({})\n",
    "    NO_BROKER_LIST['Availaible'] =title\n",
    "    NO_BROKER_LIST['Locality'] =loc\n",
    "    NO_BROKER_LIST['Total_AREA']=area\n",
    "    NO_BROKER_LIST['Pricre']=price\n",
    "    NO_BROKER_LIST['Monthly_EMI'] =emi\n",
    "    return NO_BROKER_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** NO BROKER LIST ****\n",
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Availaible</th>\n",
       "      <th>Locality</th>\n",
       "      <th>Total_AREA</th>\n",
       "      <th>Pricre</th>\n",
       "      <th>Monthly_EMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Hebba...</td>\n",
       "      <td>Independent House, Bangalore - Hosur Road, Nea...</td>\n",
       "      <td>1,800 sqft</td>\n",
       "      <td>₹1.5 Crores</td>\n",
       "      <td>₹85,971/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Elect...</td>\n",
       "      <td>Independent House, surya nagar face 1</td>\n",
       "      <td>3,000 sqft</td>\n",
       "      <td>₹2.5 Crores</td>\n",
       "      <td>₹1.43 Lacs/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Elect...</td>\n",
       "      <td>Independent House, Hosur Rd,Near Infosys Limited</td>\n",
       "      <td>1,200 sqft</td>\n",
       "      <td>₹75 Lacs</td>\n",
       "      <td>₹42,985/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Anant...</td>\n",
       "      <td>Independent House, Glass factory Outlet nd cro...</td>\n",
       "      <td>2,200 sqft</td>\n",
       "      <td>₹80 Lacs</td>\n",
       "      <td>₹45,851/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 BHK Flat  For Sale  In Sobha Silicon Oasis  ...</td>\n",
       "      <td>Sobha Silicon Oasis Naganathapura, Rayasandra ...</td>\n",
       "      <td>1,879 sqft</td>\n",
       "      <td>₹1.55 Crores</td>\n",
       "      <td>₹88,837/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4 BHK Apartment  For Sale  In Gopalan Gardenia...</td>\n",
       "      <td>Gopalan Gardenia  Gopalan gardenia, Veerasandr...</td>\n",
       "      <td>2,650 sqft</td>\n",
       "      <td>₹1.2 Crores</td>\n",
       "      <td>₹68,777/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4 BHK For Sale  In Gpr Royale In Gpr Royale</td>\n",
       "      <td>6th Cross</td>\n",
       "      <td>3,100 sqft</td>\n",
       "      <td>₹1.5 Crores</td>\n",
       "      <td>₹85,971/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4 BHK Flat  For Sale  In Electronic City</td>\n",
       "      <td>Standalone Building, Shikaripalya near Shams S...</td>\n",
       "      <td>1,400 sqft</td>\n",
       "      <td>₹35 Lacs</td>\n",
       "      <td>₹20,060/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Sarja...</td>\n",
       "      <td>Independent House,  Shantipura Village , S.P L...</td>\n",
       "      <td>1,100 sqft</td>\n",
       "      <td>₹70 Lacs</td>\n",
       "      <td>₹40,120/Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Nagan...</td>\n",
       "      <td>Independent House, Doddanagamangala Rd opposit...</td>\n",
       "      <td>1,500 sqft</td>\n",
       "      <td>₹80 Lacs</td>\n",
       "      <td>₹45,851/Month</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Availaible  \\\n",
       "0  4 BHK In Independent House  For Sale  In Hebba...   \n",
       "1  4 BHK In Independent House  For Sale  In Elect...   \n",
       "2  4 BHK In Independent House  For Sale  In Elect...   \n",
       "3  4 BHK In Independent House  For Sale  In Anant...   \n",
       "4  4 BHK Flat  For Sale  In Sobha Silicon Oasis  ...   \n",
       "5  4 BHK Apartment  For Sale  In Gopalan Gardenia...   \n",
       "6        4 BHK For Sale  In Gpr Royale In Gpr Royale   \n",
       "7           4 BHK Flat  For Sale  In Electronic City   \n",
       "8  4 BHK In Independent House  For Sale  In Sarja...   \n",
       "9  4 BHK In Independent House  For Sale  In Nagan...   \n",
       "\n",
       "                                            Locality  Total_AREA  \\\n",
       "0  Independent House, Bangalore - Hosur Road, Nea...  1,800 sqft   \n",
       "1              Independent House, surya nagar face 1  3,000 sqft   \n",
       "2   Independent House, Hosur Rd,Near Infosys Limited  1,200 sqft   \n",
       "3  Independent House, Glass factory Outlet nd cro...  2,200 sqft   \n",
       "4  Sobha Silicon Oasis Naganathapura, Rayasandra ...  1,879 sqft   \n",
       "5  Gopalan Gardenia  Gopalan gardenia, Veerasandr...  2,650 sqft   \n",
       "6                                          6th Cross  3,100 sqft   \n",
       "7  Standalone Building, Shikaripalya near Shams S...  1,400 sqft   \n",
       "8  Independent House,  Shantipura Village , S.P L...  1,100 sqft   \n",
       "9  Independent House, Doddanagamangala Rd opposit...  1,500 sqft   \n",
       "\n",
       "         Pricre       Monthly_EMI  \n",
       "0   ₹1.5 Crores     ₹85,971/Month  \n",
       "1   ₹2.5 Crores  ₹1.43 Lacs/Month  \n",
       "2      ₹75 Lacs     ₹42,985/Month  \n",
       "3      ₹80 Lacs     ₹45,851/Month  \n",
       "4  ₹1.55 Crores     ₹88,837/Month  \n",
       "5   ₹1.2 Crores     ₹68,777/Month  \n",
       "6   ₹1.5 Crores     ₹85,971/Month  \n",
       "7      ₹35 Lacs     ₹20,060/Month  \n",
       "8      ₹70 Lacs     ₹40,120/Month  \n",
       "9      ₹80 Lacs     ₹45,851/Month  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('**** NO BROKER LIST ****')\n",
    "url = \"https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44NDUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&propertyAge=0&radius=2.0\"\n",
    "html_chk  =no_broker(url)\n",
    "html_chk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
